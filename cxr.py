# -*- coding: utf-8 -*-
"""CXR.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mo7xB8gws2ev7xbbAD-GBOQ-KNLR_yj1

1. 準備
"""

!pip install chainercv  # ChainerCVのインストール

import chainer
import cupy
import chainercv
import matplotlib

chainer.print_runtime_info()
print('ChainerCV:', chainercv.__version__)
print('matplotlib:', matplotlib.__version__)

from google.colab import drive
drive.mount('/content/drive')

"""2. dataの取り込み、整形"""

#!unzip "/content/drive/My Drive/Colab Notebooks/CheXpert-v1.0-small.zip"

import csv
traincsvf = open('/content/drive/My Drive/Colab Notebooks/train.csv','r',encoding='utf-8')
validcsvf = open('/content/drive/My Drive/Colab Notebooks/valid.csv','r',encoding='utf-8')
reader1 = csv.DictReader(traincsvf)
reader2 = csv.DictReader(validcsvf)
cnt = 0;
for row in reader1:
  if (cnt>10):
    break
  print(row)
  cnt+=1

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
import chainer
import cv2
import os

choiceA = "Support Devices"
choiceB = "Pneumonia"
#train:mod10000で1-2000の12000data
trainsize = 7000 #適宜変更
cnter = 0
datasetTrain=[]
ATrain=[]
BTrain=[]
datasetValid=[]
AValid=[]
BValid=[]
for row in reader1:
  if (cnter>trainsize):
    break
  if os.path.exists('/content/drive/My Drive/Colab Notebooks/'+row['Path']):
    if (row['Frontal/Lateral']=='Frontal'):
      cnter+=1
      img = Image.open('/content/drive/My Drive/Colab Notebooks/'+row['Path'])
      img = chainer.links.model.vision.vgg.prepare(img)
      if (cnter%2200<2100):
        datasetTrain.append(img)
        if (row[choiceA]=='1.0'):
          ATrain.append(np.array(1,dtype='int'))
        else:
          ATrain.append(np.array(0,dtype='int'))
        if (row[choiceB]=='1.0'):
          BTrain.append(np.array(1,dtype='int'))
        else:
          BTrain.append(np.array(0,dtype='int'))
      else:
        datasetValid.append(img)
        if (row[choiceA]=='1.0'):
          AValid.append(np.array(1,dtype='int'))
        else:
          AValid.append(np.array(0,dtype='int'))
        if (row[choiceB]=='1.0'):
          BValid.append(np.array(1,dtype='int'))
        else:
          BValid.append(np.array(0,dtype='int'))
      if (cnter%100==0):
        print(cnter)
datasetTrain = np.array(datasetTrain)
ATrain = np.array(ATrain)
BTrain = np.array(BTrain)
print("Train",datasetTrain.shape, ATrain.shape, BTrain.shape)
datasetValid = np.array(datasetValid)
AValid = np.array(AValid)
BValid = np.array(BValid)
print("valid",datasetValid.shape, AValid.shape, BValid.shape)

np.savez("/content/drive/My Drive/Colab Notebooks/traindatasets",datasetTrain=datasetTrain,ATrain=ATrain,BTrain=BTrain)
np.savez("/content/drive/My Drive/Colab Notebooks/validdatasets",datasetValid=datasetValid,AValid=AValid,BValid=BValid)

testsize = 300 # 適宜変更
cnter = 0
datasetTest=[]
ATest=[]
BTest=[]
for row in reader2:
  if (cnter>testsize):
    break
  if os.path.exists('/content/drive/My Drive/Colab Notebooks/'+row['Path']):
    if (row['Frontal/Lateral']=='Frontal'):
      img = Image.open('/content/drive/My Drive/Colab Notebooks/'+row['Path'])
      img = chainer.links.model.vision.vgg.prepare(img)
      datasetTest.append(img)
      if (row[choiceA]=='0.0'):
        ATest.append(np.array(0,dtype='int'))
      else:
        ATest.append(np.array(1,dtype='int'))
      if (row[choiceB]=='0.0'):
        BTest.append(np.array(0,dtype='int'))
      else:
        BTest.append(np.array(1,dtype='int'))
    cnter+=1
  if (cnter%20==0):
    print(cnter)
datasetTest = np.array(datasetTest)
ATest = np.array(ATest)
BTest = np.array(BTest)
print(datasetTest.shape, ATest.shape, BTest.shape)

#もうやらなくて良い
np.savez("/content/drive/My Drive/Colab Notebooks/testdatasets",datasetTest=datasetTest,ATest=ATest,BTest=BTest)

#print(ATrain)

#print(AValid)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
import chainer
import cv2
import os
traindatasets = np.load("/content/drive/My Drive/Colab Notebooks/traindatasets.npz",allow_pickle=True)
validdatasets = np.load("/content/drive/My Drive/Colab Notebooks/validdatasets.npz",allow_pickle=True)
testdatasets = np.load("/content/drive/My Drive/Colab Notebooks/testdatasets.npz",allow_pickle=True)
datasetTrain =traindatasets['datasetTrain']
datasetValid =validdatasets['datasetValid']
datasetTest = testdatasets['datasetTest']
ATrain =traindatasets['ATrain']
AValid =validdatasets['AValid']
ATest =testdatasets['ATest']

"""画像表示テスト"""

for i in range(1):#len(datasetTrain)):
  print(datasetTrain[i])

#for i in range(len(ATrain)):
#  print(ATrain[i])

train_dataset = chainer.datasets.TupleDataset(datasetTrain,ATrain)
valid_dataset = chainer.datasets.TupleDataset(datasetValid,AValid)
test_dataset = chainer.datasets.TupleDataset(datasetTest,ATest)
#print(train_dataset[5])

x = int(input())
train1 = datasetValid[x]
pl1 = AValid[x]
#plt.imshow(train1,cmap='gray') #(h,w,c)を (c,h,w)に変えたので表示できない
#plt.show()
#print(train1)
#print(train1.shape, train1.dtype)
print("Support Devices: ", pl1)
#print("Pneumonia: ",pn1)

from chainer import iterators
batchsize = 128
train_iter = iterators.SerialIterator(train_dataset,batchsize) #serialiteratorの形にする
valid_iter = iterators.SerialIterator(valid_dataset,batchsize,repeat=False,shuffle=False)
test_iter = iterators.SerialIterator(test_dataset,batchsize,repeat=False,shuffle=False)

minibatch = train_iter.next()
print('batchsize:', len(minibatch))
print(len(minibatch))
print(len(minibatch[0]))
x, pl = minibatch[5]
print(x.shape)
print(x.dtype)
print(pl)

"""3. 学習モデル(VGG16)"""

import chainer
import chainer.functions as F
import chainer.links as L
from chainer import optimizers
 
class CXR16(chainer.Chain):
    def __init__(self, out_size=2):
        super(CXR16, self).__init__()
        with self.init_scope():
          self.base = L.VGG16Layers()
          self.fc8 = L.Linear(4096,out_size)

    def __call__(self, x):
        h = self.base(x, layers=['fc7'])['fc7']
        return self.fc8(h)

import numpy as np
from chainer.dataset import concat_examples
from chainer.cuda import to_cpu
from chainer import Reporter, report, report_scope

reporter = Reporter()
observer = object()
reporter.add_observer('my_observer:', observer)
gpu_id = 0
net = L.Classifier(CXR16())
x = []
t = []
x0,t0 = train_dataset[0]
x.append(x0)
t.append(t0)
x = np.array(x)
t = np.array(t)
print(x.shape)
print(net(x))
y = net(x,t)
print("learned result: ",y)
print("answer: ",t)

"""4. 学習"""

from chainer import training
from chainer.training import extensions

optimizer = optimizers.Adam(weight_decay_rate=0.001).setup(L.Classifier(net))
updater = training.StandardUpdater(train_iter, optimizer, device=gpu_id)
max_epoch = 20

trainer = training.Trainer(updater, (max_epoch, 'epoch'), out='/content/drive/My Drive/Colab Notebooks/results2')
trainer.extend(extensions.LogReport())
trainer.extend(extensions.snapshot(filename='snapshot_epoch-{.updater.epoch}'))
trainer.extend(extensions.Evaluator(valid_iter, net, device=gpu_id), name='val')
trainer.extend(extensions.PrintReport(['epoch', 'main/loss', 'main/accuracy', 'val/main/loss', 'val/main/accuracy', 'l1/W/data/std', 'elapsed_time']))
#trainer.extend(extensions.ParameterStatistics(net.predictor.l1, {'std': np.std}))
#trainer.extend(extensions.PlotReport(['l1/W/data/std'], x_key='epoch', file_name='std.png'))
trainer.extend(extensions.PlotReport(['main/loss', 'val/main/loss'], x_key='epoch', file_name='loss.png'))
trainer.extend(extensions.PlotReport(['main/accuracy', 'val/main/accuracy'], x_key='epoch', file_name='accuracy.png'))
trainer.extend(extensions.dump_graph('main/loss'))

trainer.run()

from chainer import serializers
serializers.save_npz('/content/drive/My Drive/Colab Notebooks/results/cxrparam2.model', net)

"""5. 評価"""

test_evaluator = extensions.Evaluator(test_iter, net, device=gpu_id)
results = test_evaluator()
print('Test accuracy:', results['main/accuracy'])

testans=[]
testresults=[]
serializers.load_npz('/content/drive/My Drive/Colab Notebooks/results/cxrparam.model', infer_model)

from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
print("accuracy: ",accuracy_score(testans,testresults)) #正解率
print("precision: ",precision_score(testans,testresults)) #PPV
print("recall: ",recall_score(testans,testresults)) #感度
print("f score: ",f1_score(testans,testresults)) #f値

from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score
import numpy as np
import matplotlib.pyplot as plt

fpr,tpr,threshold = roc_curve(testans,testresults)
plt.plot(fpr, tpr, marker='o')
plt.xlabel('FPR: False positive rate')
plt.ylabel('TPR: True positive rate')
plt.grid()
plt.savefig('/content/Drive/My Drive/Colab Notebooks/results/roc_curve.png')

testansnp = np.array(testans)
testresultsnp = np.array(testresultsnp)
print(roc_auc_score(testansnp, testresultsnp)) #AUC